# backend/app/services/ai_orchestrator.py
"""
AI Orchestration using LangGraph.
Manages multi-agent workflows for content extraction, generation, and optimization.
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import asyncio
import json

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict

from app.config import settings
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


# ============================================================================
# STATE DEFINITIONS FOR LANGGRAPH
# ============================================================================

class ContentExtractionState(TypedDict):
    """State for content extraction workflow"""
    url: str
    source_type: str
    raw_text: str
    cleaned_text: str
    summary: str
    key_points: List[str]
    metadata: Dict[str, Any]
    error: Optional[str]


class ContentGenerationState(TypedDict):
    """State for content generation workflow"""
    content: Dict[str, Any]
    content_types: List[str]
    tone: str
    target_audience: Optional[str]
    include_hashtags: bool
    generated_outputs: Dict[str, Any]
    error: Optional[str]


# ============================================================================
# AGENT NODES
# ============================================================================

class ContentExtractionAgent:
    """Extracts and processes raw content from URLs"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.MODEL_VISION,
            api_key=settings.OPENAI_API_KEY,
            temperature=0.3,
        )
    
    async def extract_text_from_youtube(self, url: str) -> str:
        """Extract transcript from YouTube video"""
        try:
            # Try using youtube-transcript-api
            try:
                from youtube_transcript_api import YouTubeTranscriptApi
                video_id = url.split(\"v=\")[1].split(\"&\")[0]
                transcript = YouTubeTranscriptApi.get_transcript(video_id)\n                text = \" \".join([item[\"text\"] for item in transcript])\n                return text\n            except Exception as e:\n                logger.warning(f\"Could not extract transcript: {e}\")\n                # Fallback: use yt-dlp for comments/metadata\n                return f\"YouTube video from URL: {url}\"\n        except Exception as e:\n            logger.error(f\"Error extracting YouTube content: {e}\")\n            raise\n    \n    async def extract_text_from_article(self, url: str) -> str:\n        \"\"\"Extract text from article URL\"\"\"\n        try:\n            import httpx\n            from bs4 import BeautifulSoup\n            \n            async with httpx.AsyncClient(timeout=10.0) as client:\n                response = await client.get(url)\n                response.raise_for_status()\n            \n            soup = BeautifulSoup(response.text, \"html.parser\")\n            \n            # Remove script and style elements\n            for script in soup([\"script\", \"style\"]):\n                script.decompose()\n            \n            text = soup.get_text()\n            lines = (line.strip() for line in text.splitlines())\n            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n            text = \" \".join(chunk for chunk in chunks if chunk)\n            \n            return text\n        except Exception as e:\n            logger.error(f\"Error extracting article content: {e}\")\n            raise\n    \n    async def process_extraction_state(self, state: ContentExtractionState) -> ContentExtractionState:\n        \"\"\"Main extraction node\"\"\"\n        try:\n            logger.info(f\"Extracting content from {state['source_type']}: {state['url']}\")\n            \n            # Extract raw text based on source type\n            if state[\"source_type\"] == \"youtube\":\n                raw_text = await self.extract_text_from_youtube(state[\"url\"])\n            elif state[\"source_type\"] == \"article\":\n                raw_text = await self.extract_text_from_article(state[\"url\"])\n            else:\n                raise ValueError(f\"Unsupported source type: {state['source_type']}\")\n            \n            state[\"raw_text\"] = raw_text\n            \n            # Clean text\n            state[\"cleaned_text\"] = raw_text.strip()\n            \n            logger.info(f\"✅ Extracted {len(raw_text)} characters\")\n            return state\n            \n        except Exception as e:\n            logger.error(f\"Extraction failed: {e}\")\n            state[\"error\"] = str(e)\n            return state\n\n\nclass ContentSummarizationAgent:\n    \"\"\"Summarizes and extracts key points from content\"\"\"\n    \n    def __init__(self):\n        self.llm = ChatOpenAI(\n            model=settings.MODEL_MAIN,\n            api_key=settings.OPENAI_API_KEY,\n            temperature=0.3,\n            max_tokens=2000,\n        )\n    \n    async def summarize(self, text: str) -> tuple[str, List[str]]:\n        \"\"\"Summarize content and extract key points\"\"\"\n        try:\n            from langchain.prompts import PromptTemplate\n            from langchain.chains import LLMChain\n            \n            # Split long text into chunks\n            splitter = RecursiveCharacterTextSplitter(\n                chunk_size=3000,\n                chunk_overlap=200,\n            )\n            chunks = splitter.split_text(text)\n            \n            # Summarize each chunk\n            summaries = []\n            for chunk in chunks[:5]:  # Use first 5 chunks to avoid token limits\n                prompt = PromptTemplate(\n                    input_variables=[\"text\"],\n                    template=\"\"\"Summarize the following text in 2-3 sentences:\n{text}\n\nSummary:\"\"\"\n                )\n                chain = LLMChain(llm=self.llm, prompt=prompt)\n                summary = await chain.arun(text=chunk)\n                summaries.append(summary.strip())\n            \n            # Extract key points\n            full_summary = \" \".join(summaries)\n            \n            prompt = PromptTemplate(\n                input_variables=[\"text\"],\n                template=\"\"\"Extract 3-5 key points from the following content as a JSON array:\n{text}\n\nRespond ONLY with valid JSON like: [\"point 1\", \"point 2\", ...]\"\"\"\n            )\n            chain = LLMChain(llm=self.llm, prompt=prompt)\n            key_points_str = await chain.arun(text=full_summary)\n            \n            try:\n                key_points = json.loads(key_points_str)\n            except json.JSONDecodeError:\n                key_points = [\"Unable to extract key points\"]\n            \n            return full_summary, key_points\n            \n        except Exception as e:\n            logger.error(f\"Summarization failed: {e}\")\n            return \"\", []\n    \n    async def process_summarization_state(self, state: ContentExtractionState) -> ContentExtractionState:\n        \"\"\"Summarization node\"\"\"\n        try:\n            logger.info(\"Summarizing content...\")\n            \n            summary, key_points = await self.summarize(state[\"cleaned_text\"])\n            state[\"summary\"] = summary\n            state[\"key_points\"] = key_points\n            \n            logger.info(f\"✅ Extracted {len(key_points)} key points\")\n            return state\n            \n        except Exception as e:\n            logger.error(f\"Summarization node failed: {e}\")\n            state[\"error\"] = str(e)\n            return state\n\n\nclass ContentGenerationAgent:\n    \"\"\"Generates multi-format social media content\"\"\"\n    \n    def __init__(self):\n        self.llm = ChatOpenAI(\n            model=settings.MODEL_MAIN,\n            api_key=settings.OPENAI_API_KEY,\n            temperature=0.7,\n            max_tokens=1500,\n        )\n    \n    async def generate_linkedin_carousel(self, content: Dict[str, Any], **kwargs) -> List[str]:\n        \"\"\"Generate LinkedIn carousel posts (5-7 slides)\"\"\"\n        try:\n            prompt = f\"\"\"Create a 5-slide LinkedIn carousel about the following:\n\nTitle: {content.get('summary', '')}\n\nKey points:\n{chr(10).join(['- ' + kp for kp in content.get('key_points', [])])}\n\nTone: {kwargs.get('tone', 'professional')}\nTarget audience: {kwargs.get('target_audience', 'professionals')}\n\nFor each slide, provide ONLY the text content, numbered 1-5. Make it engaging and actionable.\n\nSlide 1:\n\"\"\"\n            \n            from langchain.prompts import PromptTemplate\n            from langchain.chains import LLMChain\n            \n            chain = LLMChain(llm=self.llm, prompt=PromptTemplate(\n                input_variables=[],\n                template=prompt\n            ))\n            result = await chain.arun()\n            \n            slides = result.split(\"Slide\")\n            return [s.strip() for s in slides if s.strip()]\n        except Exception as e:\n            logger.error(f\"LinkedIn generation failed: {e}\")\n            return []\n    \n    async def generate_twitter_thread(self, content: Dict[str, Any], **kwargs) -> List[str]:\n        \"\"\"Generate Twitter thread (5-10 tweets)\"\"\"\n        try:\n            prompt = f\"\"\"Create a Twitter thread about:\n{content.get('summary', '')}\n\nMake 5-7 engaging tweets. Each tweet should be under 280 characters.\n\nInclude hashtags: {kwargs.get('include_hashtags', True)}\n\nTweet 1:\n\"\"\"\n            \n            from langchain.prompts import PromptTemplate\n            from langchain.chains import LLMChain\n            \n            chain = LLMChain(llm=self.llm, prompt=PromptTemplate(\n                input_variables=[],\n                template=prompt\n            ))\n            result = await chain.arun()\n            \n            tweets = result.split(\"Tweet\")\n            return [t.strip() for t in tweets if t.strip()]\n        except Exception as e:\n            logger.error(f\"Twitter generation failed: {e}\")\n            return []\n    \n    async def generate_blog_post(self, content: Dict[str, Any], **kwargs) -> str:\n        \"\"\"Generate full blog post\"\"\"\n        try:\n            prompt = f\"\"\"Write a compelling blog post based on:\n\nSummary: {content.get('summary', '')}\n\nKey points:\n{chr(10).join(['- ' + kp for kp in content.get('key_points', [])])}\n\nMake it 800-1000 words, with:\n- An engaging introduction\n- Main body with 3-4 sections\n- A conclusion with call-to-action\n\"\"\"\n            \n            from langchain.prompts import PromptTemplate\n            from langchain.chains import LLMChain\n            \n            chain = LLMChain(llm=self.llm, prompt=PromptTemplate(\n                input_variables=[],\n                template=prompt\n            ))\n            result = await chain.arun()\n            \n            return result.strip()\n        except Exception as e:\n            logger.error(f\"Blog post generation failed: {e}\")\n            return \"\"\n    \n    async def process_generation_state(self, state: ContentGenerationState) -> ContentGenerationState:\n        \"\"\"Main generation node\"\"\"\n        try:\n            logger.info(f\"Generating {len(state['content_types'])} content types...\")\n            \n            generated = {}\n            \n            for content_type in state[\"content_types\"]:\n                if content_type == \"linkedin_carousel\":\n                    slides = await self.generate_linkedin_carousel(\n                        state[\"content\"],\n                        tone=state[\"tone\"],\n                        target_audience=state[\"target_audience\"],\n                    )\n                    generated[\"linkedin_carousel\"] = {\"slides\": slides}\n                \n                elif content_type == \"twitter_thread\":\n                    tweets = await self.generate_twitter_thread(\n                        state[\"content\"],\n                        include_hashtags=state[\"include_hashtags\"],\n                    )\n                    generated[\"twitter_thread\"] = {\"tweets\": tweets}\n                \n                elif content_type == \"blog_post\":\n                    post = await self.generate_blog_post(state[\"content\"])\n                    generated[\"blog_post\"] = {\"content\": post}\n            \n            state[\"generated_outputs\"] = generated\n            logger.info(f\"✅ Generated content for {len(generated)} types\")\n            return state\n            \n        except Exception as e:\n            logger.error(f\"Generation failed: {e}\")\n            state[\"error\"] = str(e)\n            return state\n\n\n# ============================================================================
# AI ORCHESTRATOR CLASS
# ============================================================================

class AIOrchestrator:\n    \"\"\"Orchestrates multi-agent workflows using LangGraph\"\"\"\n    \n    def __init__(self):\n        self.extraction_agent = ContentExtractionAgent()\n        self.summarization_agent = ContentSummarizationAgent()\n        self.generation_agent = ContentGenerationAgent()\n    \n    async def extract_content(self, url: str, source_type: str) -> Dict[str, Any]:\n        \"\"\"Extract and process content from URL\"\"\"\n        \n        # Initial state\n        state: ContentExtractionState = {\n            \"url\": url,\n            \"source_type\": source_type,\n            \"raw_text\": \"\",\n            \"cleaned_text\": \"\",\n            \"summary\": \"\",\n            \"key_points\": [],\n            \"metadata\": {},\n            \"error\": None,\n        }\n        \n        # Extract\n        state = await self.extraction_agent.process_extraction_state(state)\n        \n        if state[\"error\"]:\n            raise Exception(state[\"error\"])\n        \n        # Summarize\n        state = await self.summarization_agent.process_summarization_state(state)\n        \n        if state[\"error\"]:\n            raise Exception(state[\"error\"])\n        \n        return {\n            \"text\": state[\"cleaned_text\"],\n            \"summary\": state[\"summary\"],\n            \"key_points\": state[\"key_points\"],\n            \"metadata\": state[\"metadata\"],\n        }\n    \n    async def generate_content(\n        self,\n        content: Dict[str, Any],\n        content_types: List[str],\n        tone: str = \"professional\",\n        target_audience: Optional[str] = None,\n        include_hashtags: bool = True,\n    ) -> Dict[str, Any]:\n        \"\"\"Generate multi-format content\"\"\"\n        \n        state: ContentGenerationState = {\n            \"content\": content,\n            \"content_types\": content_types,\n            \"tone\": tone,\n            \"target_audience\": target_audience,\n            \"include_hashtags\": include_hashtags,\n            \"generated_outputs\": {},\n            \"error\": None,\n        }\n        \n        state = await self.generation_agent.process_generation_state(state)\n        \n        if state[\"error\"]:\n            raise Exception(state[\"error\"])\n        \n        return state[\"generated_outputs\"]
